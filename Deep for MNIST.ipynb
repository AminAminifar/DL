{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('C:/Workspace/Data/MNIST')\n",
    "\n",
    "f = gzip.open(data_dir/'train-images-idx3-ubyte.gz','r')\n",
    "image_size = 28\n",
    "num_images = 60000\n",
    "\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "data = data.reshape(num_images, image_size, image_size, 1)\n",
    "\n",
    "# image = np.asarray(data[2]).squeeze()\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(data_dir/'train-labels-idx1-ubyte.gz','r')\n",
    "f.read(8)\n",
    "# for i in range(0,5):\n",
    "#     buf = f.read(1)\n",
    "#     labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "#     print(labels)\n",
    "\n",
    "buf = f.read(num_images)\n",
    "labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(data).squeeze()\n",
    "y = labels\n",
    "shape = (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=shape),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) ,\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/150\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 14.6212 - accuracy: 0.7790\n",
      "Epoch 2/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 2.9711 - accuracy: 0.9025\n",
      "Epoch 3/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.7570 - accuracy: 0.9248\n",
      "Epoch 4/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 1.2118 - accuracy: 0.9373\n",
      "Epoch 5/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.8948 - accuracy: 0.9470\n",
      "Epoch 6/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.6626 - accuracy: 0.9546\n",
      "Epoch 7/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.5263 - accuracy: 0.9615\n",
      "Epoch 8/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.4176 - accuracy: 0.9659\n",
      "Epoch 9/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.3326 - accuracy: 0.9707\n",
      "Epoch 10/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.2680 - accuracy: 0.9731\n",
      "Epoch 11/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.2128 - accuracy: 0.9768\n",
      "Epoch 12/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1720 - accuracy: 0.9798\n",
      "Epoch 13/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1422 - accuracy: 0.9820\n",
      "Epoch 14/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1119 - accuracy: 0.9851\n",
      "Epoch 15/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1039 - accuracy: 0.9850\n",
      "Epoch 16/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0898 - accuracy: 0.9865\n",
      "Epoch 17/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0715 - accuracy: 0.9880\n",
      "Epoch 18/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0574 - accuracy: 0.9898\n",
      "Epoch 19/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0454 - accuracy: 0.9914\n",
      "Epoch 20/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0499 - accuracy: 0.9908\n",
      "Epoch 21/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0414 - accuracy: 0.9920\n",
      "Epoch 22/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0316 - accuracy: 0.9934\n",
      "Epoch 23/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0268 - accuracy: 0.9945\n",
      "Epoch 24/150\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.0245 - accuracy: 0.9948\n",
      "Epoch 25/150\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0239 - accuracy: 0.9942\n",
      "Epoch 26/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0236 - accuracy: 0.9945\n",
      "Epoch 27/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0154 - accuracy: 0.9962\n",
      "Epoch 28/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0239 - accuracy: 0.9946\n",
      "Epoch 29/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0262 - accuracy: 0.9944\n",
      "Epoch 30/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0232 - accuracy: 0.9944\n",
      "Epoch 31/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0237 - accuracy: 0.9944\n",
      "Epoch 32/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0183 - accuracy: 0.9955\n",
      "Epoch 33/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0173 - accuracy: 0.9958\n",
      "Epoch 34/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0148 - accuracy: 0.9965\n",
      "Epoch 35/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0249 - accuracy: 0.9944\n",
      "Epoch 36/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0327 - accuracy: 0.9931\n",
      "Epoch 37/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0379 - accuracy: 0.9927\n",
      "Epoch 38/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0317 - accuracy: 0.9933\n",
      "Epoch 39/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0272 - accuracy: 0.9943\n",
      "Epoch 40/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0311 - accuracy: 0.9938\n",
      "Epoch 41/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0320 - accuracy: 0.9936\n",
      "Epoch 42/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0303 - accuracy: 0.9938\n",
      "Epoch 43/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0272 - accuracy: 0.9948\n",
      "Epoch 44/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0187 - accuracy: 0.9960\n",
      "Epoch 45/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0132 - accuracy: 0.9970\n",
      "Epoch 46/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0195 - accuracy: 0.9959\n",
      "Epoch 47/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0118 - accuracy: 0.9973\n",
      "Epoch 48/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0135 - accuracy: 0.9970\n",
      "Epoch 49/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0192 - accuracy: 0.9958\n",
      "Epoch 50/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0243 - accuracy: 0.9957\n",
      "Epoch 51/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0219 - accuracy: 0.9956\n",
      "Epoch 52/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0371 - accuracy: 0.9939\n",
      "Epoch 53/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0294 - accuracy: 0.9952\n",
      "Epoch 54/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0306 - accuracy: 0.9948\n",
      "Epoch 55/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0359 - accuracy: 0.9943\n",
      "Epoch 56/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0358 - accuracy: 0.9939\n",
      "Epoch 57/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0434 - accuracy: 0.9934\n",
      "Epoch 58/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0508 - accuracy: 0.9928\n",
      "Epoch 59/150\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.0404 - accuracy: 0.9942\n",
      "Epoch 60/150\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.0325 - accuracy: 0.9952\n",
      "Epoch 61/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0260 - accuracy: 0.9956\n",
      "Epoch 62/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0228 - accuracy: 0.9961\n",
      "Epoch 63/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0209 - accuracy: 0.9966\n",
      "Epoch 64/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0134 - accuracy: 0.9975\n",
      "Epoch 65/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0243 - accuracy: 0.9962\n",
      "Epoch 66/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0362 - accuracy: 0.9946\n",
      "Epoch 67/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0467 - accuracy: 0.9937\n",
      "Epoch 68/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0422 - accuracy: 0.9940\n",
      "Epoch 69/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0376 - accuracy: 0.9945\n",
      "Epoch 70/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0306 - accuracy: 0.9953\n",
      "Epoch 71/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0298 - accuracy: 0.9953\n",
      "Epoch 72/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0317 - accuracy: 0.9952\n",
      "Epoch 73/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0305 - accuracy: 0.9959\n",
      "Epoch 74/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0379 - accuracy: 0.9949\n",
      "Epoch 75/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0303 - accuracy: 0.9958\n",
      "Epoch 76/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0364 - accuracy: 0.9952\n",
      "Epoch 77/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0364 - accuracy: 0.9950\n",
      "Epoch 78/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0274 - accuracy: 0.9958\n",
      "Epoch 79/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0282 - accuracy: 0.9960\n",
      "Epoch 80/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0254 - accuracy: 0.9968\n",
      "Epoch 81/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0207 - accuracy: 0.9972\n",
      "Epoch 82/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0287 - accuracy: 0.9959\n",
      "Epoch 83/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0236 - accuracy: 0.9966\n",
      "Epoch 84/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0239 - accuracy: 0.9969\n",
      "Epoch 85/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0278 - accuracy: 0.9962\n",
      "Epoch 86/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0160 - accuracy: 0.9974\n",
      "Epoch 87/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0148 - accuracy: 0.9975\n",
      "Epoch 88/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0234 - accuracy: 0.9967\n",
      "Epoch 89/150\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0232 - accuracy: 0.9967\n",
      "Epoch 90/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0310 - accuracy: 0.9961\n",
      "Epoch 91/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0417 - accuracy: 0.9953\n",
      "Epoch 92/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0570 - accuracy: 0.9935\n",
      "Epoch 93/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0293 - accuracy: 0.9962\n",
      "Epoch 94/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0238 - accuracy: 0.9969\n",
      "Epoch 95/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0166 - accuracy: 0.9973\n",
      "Epoch 96/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0212 - accuracy: 0.9969\n",
      "Epoch 97/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0167 - accuracy: 0.9977\n",
      "Epoch 98/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0201 - accuracy: 0.9971\n",
      "Epoch 99/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0231 - accuracy: 0.9969\n",
      "Epoch 100/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0294 - accuracy: 0.9965\n",
      "Epoch 101/150\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0184 - accuracy: 0.9977\n",
      "Epoch 102/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0139 - accuracy: 0.9979s - loss: 0.0139 - accuracy: 0.99\n",
      "Epoch 103/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0178 - accuracy: 0.9975\n",
      "Epoch 104/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0232 - accuracy: 0.9971\n",
      "Epoch 105/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0261 - accuracy: 0.9968\n",
      "Epoch 106/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0283 - accuracy: 0.9965\n",
      "Epoch 107/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0233 - accuracy: 0.9969\n",
      "Epoch 108/150\n",
      "60000/60000 [==============================] - 1s 15us/sample - loss: 0.0404 - accuracy: 0.9953\n",
      "Epoch 109/150\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0314 - accuracy: 0.9967\n",
      "Epoch 110/150\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.0268 - accuracy: 0.9968\n",
      "Epoch 111/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0232 - accuracy: 0.9971\n",
      "Epoch 112/150\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.0342 - accuracy: 0.9961\n",
      "Epoch 113/150\n",
      "60000/60000 [==============================] - 1s 18us/sample - loss: 0.0173 - accuracy: 0.9976\n",
      "Epoch 114/150\n",
      "60000/60000 [==============================] - 1s 14us/sample - loss: 0.0214 - accuracy: 0.9971\n",
      "Epoch 115/150\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0245 - accuracy: 0.9969\n",
      "Epoch 116/150\n",
      "60000/60000 [==============================] - 1s 12us/sample - loss: 0.0244 - accuracy: 0.9969\n",
      "Epoch 117/150\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0283 - accuracy: 0.9967\n",
      "Epoch 118/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0248 - accuracy: 0.9973\n",
      "Epoch 119/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0214 - accuracy: 0.9973\n",
      "Epoch 120/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0173 - accuracy: 0.9978\n",
      "Epoch 121/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0173 - accuracy: 0.9978\n",
      "Epoch 122/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0137 - accuracy: 0.9982\n",
      "Epoch 123/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0166 - accuracy: 0.9980\n",
      "Epoch 124/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0102 - accuracy: 0.9984\n",
      "Epoch 125/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0178 - accuracy: 0.9978\n",
      "Epoch 126/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0117 - accuracy: 0.9984\n",
      "Epoch 127/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0168 - accuracy: 0.9980\n",
      "Epoch 128/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0234 - accuracy: 0.9974\n",
      "Epoch 129/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0286 - accuracy: 0.9971\n",
      "Epoch 130/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0284 - accuracy: 0.9968\n",
      "Epoch 131/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0324 - accuracy: 0.9966\n",
      "Epoch 132/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0260 - accuracy: 0.9973\n",
      "Epoch 133/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0152 - accuracy: 0.9980\n",
      "Epoch 134/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0193 - accuracy: 0.9978\n",
      "Epoch 135/150\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0208 - accuracy: 0.9973\n",
      "Epoch 136/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0276 - accuracy: 0.9974\n",
      "Epoch 137/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0255 - accuracy: 0.9973\n",
      "Epoch 138/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0227 - accuracy: 0.9973\n",
      "Epoch 139/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0325 - accuracy: 0.9970\n",
      "Epoch 140/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0312 - accuracy: 0.9970\n",
      "Epoch 141/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0216 - accuracy: 0.9973\n",
      "Epoch 142/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0214 - accuracy: 0.9977\n",
      "Epoch 143/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0177 - accuracy: 0.9983\n",
      "Epoch 144/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0232 - accuracy: 0.9974\n",
      "Epoch 145/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0233 - accuracy: 0.9976\n",
      "Epoch 146/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0181 - accuracy: 0.9980\n",
      "Epoch 147/150\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0207 - accuracy: 0.9980\n",
      "Epoch 148/150\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0175 - accuracy: 0.9980\n",
      "Epoch 149/150\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0174 - accuracy: 0.9980\n",
      "Epoch 150/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0209 - accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X, y,\n",
    "    batch_size=1000,\n",
    "    epochs=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5. You can change this to get a different view.\n",
    "history_df.loc[5:, ['loss']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "f = gzip.open(data_dir/'t10k-images-idx3-ubyte.gz','r')\n",
    "image_size = 28\n",
    "num_images = 10000\n",
    "\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "data_test = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "data_test = data_test.reshape(num_images, image_size, image_size, 1)\n",
    "\n",
    "# image = np.asarray(data_test[2]).squeeze()\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(data_dir/'t10k-labels-idx1-ubyte.gz','r')\n",
    "f.read(8)\n",
    "# for i in range(0,5):\n",
    "#     buf = f.read(1)\n",
    "#     labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "#     print(labels)\n",
    "\n",
    "buf = f.read(num_images)\n",
    "labels_test = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_input to have 3 dimensions, but got array with shape (10000, 28, 28, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8ac05b118e5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# predictions = model.predict(data_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nTest accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    831\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m   def predict(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    454\u001b[0m     return self._model_iteration(\n\u001b[0;32m    455\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         sample_weight=sample_weight, steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[0;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2472\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    563\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected flatten_input to have 3 dimensions, but got array with shape (10000, 28, 28, 1)"
     ]
    }
   ],
   "source": [
    "# predictions = model.predict(data_test)\n",
    "test_loss, test_acc = model.evaluate(data_test,  labels_test)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
